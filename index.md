---
layout: home
title: Yaowen Ye
---

# Research Interests

I am interested in making human oversight of AI systems reliable on hard tasks and efficient for complex outputs. Some questions I am thinking about recently are:
- How can AI help humans give accurate feedback efficiently for complex model outputs that might require group of experts days to understand?
- When human feedback is prone to errors, how can AIs learn to do better than humans instead of replicating their mistakes?

In the past, I also worked on
- Cognitive reasoning: How can we explain humans' reasoning process such as intuitive physics and abductive reasoning? How do these explanations inspire understanding of AI?
- Learning on graphs: How can we better model graph data for applications like recommender systems? How can we ensure these models are designed equally for different users and responsibly for real-world deployment?
