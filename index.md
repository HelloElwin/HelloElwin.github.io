---
layout: home
title: Yaowen Ye
---

# Research Interests

- I am interested in ensuring reliable human supervision for complex AI systems that produce complex outputs.
- Questions I am thinking about recently:
    - How can we design human-AI collaboration mechanisms to amplify human oversight so that increase in human effort is minimized even as AI's complexity and compute scale?
    - When human feedback is imperfect, how can AIs learn to do better than humans without replicating their systematic errors?
    - Can models develop satisfying values purely from their own reasoning so that impact of human supervision errors is minimized?
    - What are the consequences of using AIs to supervise other AIs?
- In the past, I also worked on
    - Cognitive reasoning: How can we explain humans' reasoning process such as intuitive physics and abductive reasoning? How do these explanations inspire understanding of AI?
    - Learning on graphs: How can we better model graph data for applications like recommender systems? How can we ensure these models are designed equally for different users and responsibly for real-world deployment?
